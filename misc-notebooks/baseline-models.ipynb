{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from fenpreprocessing import fen_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from data_generation import position_generator, fix_positions, PosGen\n",
    "\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting paramaters on early stopping\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=20,\n",
    "                          verbose=1,\n",
    "                          mode='min',\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "log_dir = \"logs/fit/baseline\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Memory management, likely not necessary, but used as a safety as per the documentation recommendations on using GPUS\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train = pd.read_csv('fens/converted_train_partial.csv')\n",
    "small_val = pd.read_csv('fens/converted_val_partial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (338855, 2), Validation: (19123, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {small_train.shape}, Validation: {small_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597.59375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_val.shape[0] / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = position_generator(small_train)\n",
    "# val_gen = position_generator(small_val)\n",
    "train_gen = PosGen(small_train, 'Position', 'Target')\n",
    "val_gen = PosGen(small_val, 'Position', 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          13376     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          8224      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,497\n",
      "Trainable params: 54,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "10590/10590 [==============================] - 148s 14ms/step - loss: 0.1348 - acc: 0.9681 - val_loss: 0.1263 - val_acc: 0.9693\n",
      "Epoch 2/30\n",
      "10590/10590 [==============================] - 149s 14ms/step - loss: 0.1247 - acc: 0.9684 - val_loss: 0.1221 - val_acc: 0.9691\n",
      "Epoch 3/30\n",
      "10590/10590 [==============================] - 150s 14ms/step - loss: 0.1192 - acc: 0.9689 - val_loss: 0.1180 - val_acc: 0.9695\n",
      "Epoch 4/30\n",
      "10590/10590 [==============================] - 149s 14ms/step - loss: 0.1157 - acc: 0.9695 - val_loss: 0.1189 - val_acc: 0.9696\n",
      "Epoch 5/30\n",
      "10590/10590 [==============================] - 140s 13ms/step - loss: 0.1129 - acc: 0.9701 - val_loss: 0.1176 - val_acc: 0.9695\n",
      "Epoch 6/30\n",
      "10590/10590 [==============================] - 149s 14ms/step - loss: 0.1105 - acc: 0.9706 - val_loss: 0.1176 - val_acc: 0.9697\n",
      "Epoch 7/30\n",
      "10590/10590 [==============================] - 155s 15ms/step - loss: 0.1079 - acc: 0.9711 - val_loss: 0.1209 - val_acc: 0.9680\n",
      "Epoch 8/30\n",
      "10590/10590 [==============================] - 149s 14ms/step - loss: 0.1056 - acc: 0.9717 - val_loss: 0.1239 - val_acc: 0.9672\n",
      "Epoch 9/30\n",
      "10590/10590 [==============================] - 147s 14ms/step - loss: 0.1033 - acc: 0.9724 - val_loss: 0.1288 - val_acc: 0.9671\n",
      "Epoch 10/30\n",
      "10590/10590 [==============================] - 146s 14ms/step - loss: 0.1012 - acc: 0.9726 - val_loss: 0.1245 - val_acc: 0.9679\n",
      "Epoch 11/30\n",
      "10590/10590 [==============================] - 148s 14ms/step - loss: 0.0992 - acc: 0.9732 - val_loss: 0.1262 - val_acc: 0.9686\n",
      "Epoch 12/30\n",
      "10590/10590 [==============================] - 148s 14ms/step - loss: 0.0971 - acc: 0.9737 - val_loss: 0.1322 - val_acc: 0.9655\n",
      "Epoch 13/30\n",
      "10590/10590 [==============================] - 149s 14ms/step - loss: 0.0953 - acc: 0.9743 - val_loss: 0.1306 - val_acc: 0.9678\n",
      "Epoch 14/30\n",
      "10590/10590 [==============================] - 145s 14ms/step - loss: 0.0936 - acc: 0.9746 - val_loss: 0.1326 - val_acc: 0.9652\n",
      "Epoch 15/30\n",
      "10590/10590 [==============================] - 147s 14ms/step - loss: 0.0918 - acc: 0.9750 - val_loss: 0.1365 - val_acc: 0.9647\n",
      "Epoch 16/30\n",
      "10590/10590 [==============================] - 147s 14ms/step - loss: 0.0899 - acc: 0.9754 - val_loss: 0.1345 - val_acc: 0.9657\n",
      "Epoch 17/30\n",
      "10590/10590 [==============================] - 146s 14ms/step - loss: 0.0880 - acc: 0.9758 - val_loss: 0.1414 - val_acc: 0.9646\n",
      "Epoch 18/30\n",
      "10590/10590 [==============================] - 145s 14ms/step - loss: 0.0866 - acc: 0.9763 - val_loss: 0.1427 - val_acc: 0.9645\n",
      "Epoch 19/30\n",
      "10590/10590 [==============================] - 145s 14ms/step - loss: 0.0852 - acc: 0.9765 - val_loss: 0.1461 - val_acc: 0.9635\n",
      "Epoch 20/30\n",
      "10590/10590 [==============================] - 146s 14ms/step - loss: 0.0836 - acc: 0.9771 - val_loss: 0.1484 - val_acc: 0.9647\n",
      "Epoch 21/30\n",
      "10590/10590 [==============================] - 145s 14ms/step - loss: 0.0824 - acc: 0.9773 - val_loss: 0.1479 - val_acc: 0.9646\n",
      "Epoch 22/30\n",
      "10590/10590 [==============================] - 145s 14ms/step - loss: 0.0810 - acc: 0.9775 - val_loss: 0.1626 - val_acc: 0.9614\n",
      "Epoch 23/30\n",
      "10590/10590 [==============================] - 145s 14ms/step - loss: 0.0799 - acc: 0.9778 - val_loss: 0.1533 - val_acc: 0.9626\n",
      "Epoch 24/30\n",
      "10590/10590 [==============================] - 145s 14ms/step - loss: 0.0784 - acc: 0.9783 - val_loss: 0.1617 - val_acc: 0.9607\n",
      "Epoch 25/30\n",
      "10590/10590 [==============================] - 143s 14ms/step - loss: 0.0771 - acc: 0.9785 - val_loss: 0.1632 - val_acc: 0.9610\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Conv2D(64, 4, padding='same', input_shape=(8,8,13), activation='relu'))\n",
    "baseline_model.add(layers.MaxPooling2D(2))\n",
    "baseline_model.add(layers.Conv2D(32, 2, padding='same', activation='relu'))\n",
    "baseline_model.add(layers.Flatten())\n",
    "baseline_model.add(layers.Dense(64, activation='relu'))\n",
    "baseline_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "baseline_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['acc'])\n",
    "baseline_model.summary()\n",
    "\n",
    "# Fitting the model\n",
    "baseline_history = baseline_model.fit(x=train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    # steps_per_epoch=100,\n",
    "                    epochs=30,\n",
    "                    callbacks=[earlystop, tensorboard_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LongModel-PB/assets\n"
     ]
    }
   ],
   "source": [
    "baseline_model.save('LongModel-PB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_model.save('LongModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee0a5e5bf5625b85fe8b3503969a2ae7df2f5f7e92e10954b751982b3d5ddf25"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('chess-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
